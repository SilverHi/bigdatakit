#!/bin/bash

print_usage() {
cat <<EOF
Usage: $0 <command> [options]...

commands:
  help                             display this help text
  spark-streaming <jar> [options]  run a Spark Streaming client
  create-table <table spec file>   create hive table
  etl <jar> <logdate> [options]    run a etl job

spark-streaming options:
  -Dmaster=<url>            specify the Spark run mode, "local[*]" or "yarn-client"
  -Dname=<name>             specify the name of Spark application
  -Dapproach=<Dapproach>    specify the Kafka approach, "receiver-based" or "direct-based"
  -DzkConnString=<url>      specify the ZooKeeper connection to use
  -Dtopics=<topics>         specify the Kafka topics with comma seperated
  -DgroupId=<group>         specify the Kafka consumer group id
  -DbatchDuration=<seconds> specify the Spark Streaming batch process duration
  -Dprocessor=<class>       specify the processor class
  -DthreadNum=<num>         specify the Kafka consumer thread num (only need for "receiver-based")
  -DbrokerList=<url>        specify the kafka broker list (only need for "direct-based")
  -DoffsetsCommitBatchInterval=<interval>  specify the Kafka offsets commit batch interval  (only need for "direct-based")
  -D<property>=<value>      specify any Java system property value

etl options:
  -Dmaster=<url>            specify the Spark run mode, "local[*]" or "yarn-client"
  -Dname=<name>             specify the name of Spark application
  -Dname=<database>         specify the database
  -Dname=<table>            specify the table
  -Dprocessor=<class>       specify the processor class

EOF
}

submit_spark_streaming() {
  userJar=$1; shift
  if [[ `ls $userJar >/dev/null 2>&1; echo $?` -ne 0 ]]; then
    echo "$userJar is not existed"
    exit 1
  fi

  USER_JAR=`readlink -f $userJar`
  LOCAL_CLASSPATH=$SPARK_CONF_DIR:$SPARK_ASSEMBLY_JAR:$BIGDATAKIT_CONF_DIR:$BIGDATAKIT_CLASSPATH:$SPARK_CLASSPATH:$USER_JAR
  SPARK_JARS=`classpath_to_sparkjars $BIGDATAKIT_CLASSPATH:$USER_JAR`
  JAVA_OPTS=`echo " $@" | sed "s/[ \t]-D/ -Droot.sparkStreaming./g"`
  MAIN_CLASS="com.sogou.bigdatakit.streaming.SparkStreaming"

  $JAVA_HOME/bin/java -Djava.library.path=$LD_LIBRARY_PATH $JAVA_OPTS -Dspark.jars=$SPARK_JARS -cp $LOCAL_CLASSPATH $MAIN_CLASS
}

create_table() {
  LOCAL_CLASSPATH=$SPARK_CONF_DIR:$SPARK_ASSEMBLY_JAR:$BIGDATAKIT_CONF_DIR:$BIGDATAKIT_CLASSPATH:$SPARK_CLASSPATH:$HIVE_AUXLIB_CLASSPATH
  MAIN_CLASS="com.sogou.bigdatakit.hive.CreateTable"

  $JAVA_HOME/bin/java -Djava.library.path=$LD_LIBRARY_PATH -XX:MaxPermSize=256m -cp $LOCAL_CLASSPATH $MAIN_CLASS $@
}

etl() {
  userJar=$1; shift
  if [[ `ls $userJar >/dev/null 2>&1; echo $?` -ne 0 ]]; then
    echo "$userJar is not existed"
    exit 1
  fi
  logdate=$1; shift

  USER_JAR=`readlink -f $userJar`
  LOCAL_CLASSPATH=$SPARK_CONF_DIR:$SPARK_ASSEMBLY_JAR:$BIGDATAKIT_CONF_DIR:$BIGDATAKIT_CLASSPATH:$SPARK_CLASSPATH:$USER_JAR:$HIVE_AUXLIB_CLASSPATH
  SPARK_JARS=`classpath_to_sparkjars $BIGDATAKIT_CLASSPATH:$USER_JAR:$HIVE_AUXLIB_CLASSPATH`
  JAVA_OPTS=`echo " $@" | sed "s/[ \t]-D/ -Droot.hive.etl./g"`
  MAIN_CLASS="com.sogou.bigdatakit.hive.etl.ETL"

  $JAVA_HOME/bin/java -Djava.library.path=$LD_LIBRARY_PATH -Xmx1G -XX:MaxPermSize=256M $JAVA_OPTS -Dspark.jars=$SPARK_JARS -cp $LOCAL_CLASSPATH $MAIN_CLASS $logdate
}

classpath_to_sparkjars() {
  echo $1 | awk 'BEGIN{RS=":";ORS=","}{if($1!=""){print "file://"$1}}'
}


dir=`dirname $0`
dir=`cd $dir/..; pwd`

. $dir/conf/bigdatakit-env.sh

COMMAND=$1; shift

case $COMMAND in
  help)
    print_usage
    exit
    ;;

  spark-streaming)
    submit_spark_streaming $@
    exit
    ;;

  create-table)
    create_table $@
    exit
    ;;

  etl)
    etl $@
    exit
    ;;

  *)
    print_usage
    exit
    ;;
esac